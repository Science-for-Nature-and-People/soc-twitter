---
title: "phrases"
author: "Meilin"
date: "7/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### This markdown visualizes the common flow of words in tweets by using quanteda package to catch phrases. These visualizations are separated into: the full noRT dataset, top 25 tweets, top 100 tweets, tweets excluding top 100, and then repeat this by breaking out phrases by search terms: soil health | soil fertility | soil quality | rangeland health | regenerative agriculture.

```{r, include=FALSE}
# load packages
library(tidyverse)
library(tidytext)
library(stringr)
library(ggraph)
library(igraph)
library(tm)
library(NLP)
library(quanteda)
library(SnowballC)
source("../text_analysis_functions.R")

# load data
noRT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v4/twitter_merged_noRT_v4.csv", stringsAsFactors = FALSE) 
```


```{r, include=FALSE}
# select top 25 and 100 tweets based on their retweet count
# use a sample in the following code

noRT_clean <- clean_data(noRT, rm_pope = T, rm_india = F)

top_25_noRT <- noRT_clean %>%
  arrange(-retweet_count) %>%
  head(25)

top_100_noRT <- noRT_clean %>% 
  arrange(-retweet_count) %>% 
  head(100)

rest_noRT <- noRT_clean %>% 
  arrange(-retweet_count) %>%
  slice(101:n())
```

***

# detect phrases using the full noRT dataset
```{r}
tstat_col_caps <- phrases(noRT_clean, 100)

head(tstat_col_caps, 100)
```

# Compare the phrases from the top 25, top 100 to the rest
```{r}
# top 25 noRT
tstat_col_caps_25 <- phrases(top_25_noRT, 2)

head(tstat_col_caps_25, 50) 
```

```{r}
# top 100 noRT
tstat_col_caps_100 <- phrases(top_100_noRT, 2)

head(tstat_col_caps_100, 50) 
```

```{r}
# compared to the rest (exclude the top 100)
tstat_col_caps_rest <- phrases(rest_noRT, 100)

head(tstat_col_caps_rest, 100)
```

***
---------------------------------------------
# Break out the common phrases by search term

```{r}
### creating dataset for each seach term
#### soil health
input <- noRT_clean

soil_health_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil health","#soilhealth","healthy soil","#healthysoil"), collapse = '|')))
soil_health_tweets$hits <- "soil health"

#### soil quality
soil_quality_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil quality","#soilquality"),collapse = '|')))
soil_quality_tweets$hits <- "soil quality"

### soil fertility
soil_fertility_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil fertility","#soilfertility"),collapse = '|')))
soil_fertility_tweets$hits <- "soil fertility"

#### rangeland health
rangeland_health_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("rangeland health","#rangelandhealth","healthy rangelands", "#healthyrangelands"),
                                      collapse = '|')))
rangeland_health_tweets$hits <- "rangeland health"

#### regenerative agriculture
regen_agri_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("regenerative agriculture","#regenerativeagriculture"), collapse = '|')))
regen_agri_tweets$hits <- "regenerative agriculture"

```

```{r}
# detect phrases based on search term
# soil health | soil quality | soil fertility | rangeland health | regenerative agriculture
# creat tokens with the search term dataset

# soil health

soil_health_col_caps <- phrases(soil_health_tweets, 200)

counts <- head(soil_health_col_caps, 100)

##for table in manuscript
write_csv(counts[,1:2], "soil_health_phrases.csv")
```

```{r}
# soil quality

soil_quality_col_caps <- phrases(soil_quality_tweets, 20)

head(soil_quality_col_caps, 100)
```

```{r}
# soil fertility

soil_fertility_col_caps <- phrases(soil_fertility_tweets, 20)

head(soil_fertility_col_caps, 100)
```

```{r}
# rangeland health

range_health_col_caps <- phrases(rangeland_health_tweets, 2)

head(range_health_col_caps, 100)
```

```{r}
# regenerative agriculture

regen_agri_col_caps <- phrases(regen_agri_tweets, 50)

counts_regen <- head(regen_agri_col_caps, 100)

write_csv(counts_regen[,1:2], "regen_phrases.csv")

```
