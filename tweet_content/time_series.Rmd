---
title: "Time Series"
author: "Meilin"
date: "8/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### This Markdown aims to visualize the time series of query terms/ keywords

```{r, include=FALSE}
# load packages
library(tidyverse)
library(tidytext)
library(stringr)
library(ggraph)
library(igraph)
library(tm)
library(NLP)
library(quanteda)
library(SnowballC)
library(lubridate)
library(dplyr)
library(ggplot2)
source("../text_analysis_functions.R")

# load data
noRT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v2/twitter_merged_noRT_v2.csv", stringsAsFactors = FALSE) 
```

```{r, include=FALSE}
#clean data to remove numbers, usernames, websites, non-ASCII characters and outlier
noRT_clean <- removeNumbers(noRT$text)
noRT_clean <- gsub("@\\w+","",noRT_clean)
noRT_clean <- gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", noRT_clean)
noRT_clean <- gsub("#\\s+","", noRT_clean)
noRT_clean <- gsub("&amp", "", noRT_clean)
noRT_clean <- gsub("[^\x01-\x7F]", "", noRT_clean)

noRT$text <- noRT_clean
noRT <- noRT %>% 
  filter(source != "Twittascope") 

# to remove the pope
noRT <- noRT %>%
  arrange(-retweet_count) %>%
  filter(screen_name != "Pontifex")

# to remove all india related tweets
noRT_india <- flag_india(noRT)
noRT_no_india <- noRT_india %>% 
  filter(is_india == 0)
```

```{r, include=FALSE}
# select top 25 and 100 tweets based on their retweet count
# use a sample in the following code
top_25_noRT <- noRT_no_india %>%
  arrange(-retweet_count) %>%
  head(25)

top_100_noRT <- noRT_no_india %>% 
  arrange(-retweet_count) %>% 
  head(100)
```

```{r}
# creating dataset for each seach term - this will be used for analysis and to create a figure comparing the sizes of the dataframes produced by each query

# select input
#input <- top_100_noRT
input <- noRT_no_india
```

```{r}
#### soil health
soil_health_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil health","#soilhealth","healthy soil","#healthysoil"), collapse = '|')))
soil_health_tweets$hits <- "soil health"

#### soil quality
soil_quality_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil quality","#soilquality"),collapse = '|')))
soil_quality_tweets$hits <- "soil quality"

### soil fertility
soil_fertility_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("soil fertility","#soilfertility"),collapse = '|')))
soil_fertility_tweets$hits <- "soil fertility"

#### rangeland health
rangeland_health_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("rangeland health","#rangelandhealth","healthy rangelands", "#healthyrangelands"),
                                      collapse = '|')))
rangeland_health_tweets$hits <- "rangeland health"

#### regenerative agriculture
regen_agri_tweets <- input %>% 
  filter(
    str_detect(tolower(text), paste(c("regenerative agriculture","#regenerativeagriculture"), collapse = '|')))
regen_agri_tweets$hits <- "regenerative agriculture"

```

```{r}
### plot time series of the query terms 

## use querry hits
#split hits into seperate columns
df <- soil_health_tweets %>% bind_rows(soil_quality_tweets) %>% bind_rows(soil_fertility_tweets) %>% bind_rows(rangeland_health_tweets) %>% bind_rows(regen_agri_tweets)

hit_split <- separate_rows(df, hits, sep = ";") %>% filter(!is.na(hits)) 
hit_split <- hit_split %>% filter(retweet_count > 0)

#split year, month, week and date data
hit_split$created_at <- date(hit_split$created_at)
hit_split$created_year <- year(hit_split$created_at)
hit_split$created_month <- month(hit_split$created_at)
hit_split$created_week <- week(hit_split$created_at)
```

### time series based on retweet count
```{r}
# scatter plot to show time series
theme_set(theme_minimal())
p11 <- ggplot(hit_split, aes(x = date(created_at), y = hits)) + geom_point(aes(size = retweet_count))

# line graph and barplot
p21 <- ggplot(hit_split, aes(y = retweet_count, x = week(created_at), color = hits)) + 
  geom_line() + ggtitle('time series')

p31 <- ggplot(hit_split, aes(y = retweet_count, x = week(created_at), fill = hits)) +
  geom_bar(stat = "identity") + ggtitle('time series')

# heat map
#find min and max of retweet count to set the limit
min_rt = min(hit_split$retweet_count)
max_rt = max(hit_split$retweet_count)

library(gtable)
library(grid)

base_size <- 8
p_17 <- ggplot(hit_split%>% filter(created_year == 2017), aes(week(created_at), y = hits)) +
  geom_tile(aes(fill = retweet_count), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log", 
                      name = "retweet count (log scale)", 
                      limit = c(min_rt,max_rt)) + 
  labs(title = "Heat Map 2017", x = "week", y = "query term") + theme_grey(base_size = base_size)

p_18 <- ggplot(hit_split%>% filter(created_year == 2018), aes(week(created_at), y = hits)) +
  geom_tile(aes(fill = retweet_count), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log",
                      name = "retweet count (log scale)", 
                      limit = c(min_rt,max_rt)) + 
  labs(title = "Heat Map 2018", x = "week", y = "query term") + theme_grey(base_size = base_size)

p_19 <- ggplot(hit_split%>% filter(created_year == 2019), aes(week(created_at), y = hits)) +
  geom_tile(aes(fill = retweet_count), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log",
                      name = "retweet count (log scale)", 
                      limit = c(min_rt,max_rt)) + 
  labs(title = "Heat Map 2019", x = "week", y = "query term") + theme_grey(base_size = base_size)

p17 <- ggplotGrob(p_17)
p18 <- ggplotGrob(p_18)
p19 <- ggplotGrob(p_19)

heatmap_top_100 <- rbind(p17, p18, p19, size = "last")
grid.newpage()
grid.draw(heatmap_top_100)


library(gtable)
library(grid)

b_17 <- ggplot(hit_split %>% filter(created_year == 2017), 
               aes(y = retweet_count, x = week(created_at), fill = hits)) + 
        geom_bar(stat = "identity") + ggtitle('Retweet count time series 2017')

b_18 <- ggplot(hit_split %>% filter(created_year == 2018), 
               aes(y = retweet_count, x = week(created_at), fill = hits)) + 
        geom_bar(stat = "identity") + ggtitle('Retweet count time series 2018')

b_19 <- ggplot(hit_split %>% filter(created_year == 2019), 
               aes(y = retweet_count, x = week(created_at), fill = hits)) + 
        geom_bar(stat = "identity") + ggtitle('Retweet count time series 2019')

b17 <- ggplotGrob(b_17)
b18 <- ggplotGrob(b_18)
b19 <- ggplotGrob(b_19)

RT_full <- rbind(b17, b18, b19, size = "last")
grid.newpage()
grid.draw(RT_full)

```

### time series based on total tweets count
```{r}
# group tweets by week and get counts
# x is grouped week, y is counts of tweets, color coded by query words

# get counts of the occurence of each query word
group <- data.frame(hit_split$created_year, hit_split$created_week, hit_split$hits)
names(group) <- c("Year","Week","Hits")

#count value based on week and query words
library(plyr)
counts.df <- ddply(group, .(group$Year, group$Week, group$Hits), nrow)
names(counts.df) <- c("Year", "Week", "Hits", "Freq")

# scatter plot to show time series
theme_set(theme_minimal())
p12 <- ggplot(counts.df, aes(x = Week, y = Hits)) + geom_point(aes(size = Freq))

# line and bar graph
p22 <- ggplot(counts.df, aes(y = Freq, x = Week, color = Hits)) + 
  geom_line() + ggtitle('time series')

p32 <-ggplot(counts.df, aes(y = Freq, x = Week, fill = Hits)) +
  geom_bar(stat = "identity") + ggtitle('time series')

# heat map
#find min and max of retweet count to set the limit
min_f = min(counts.df$Freq)
max_f = max(counts.df$Freq)

library(gtable)
library(grid)

base_size <- 8
p_17 <- ggplot(counts.df%>% filter(Year == 2017), aes(Week, y = Hits)) +
  geom_tile(aes(fill = Freq), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log", 
                      name = "retweet count (log scale)", 
                      limit = c(min_f,max_f)) + 
  labs(title = "Heat Map 2017", x = "week", y = "query term") + theme_grey(base_size = base_size)

p_18 <- ggplot(counts.df%>% filter(Year == 2018), aes(Week, y = Hits)) +
  geom_tile(aes(fill = Freq), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log",
                      name = "retweet count (log scale)", 
                      limit = c(min_f,max_f)) + 
  labs(title = "Heat Map 2018", x = "week", y = "query term") + theme_grey(base_size = base_size)

p_19 <- ggplot(counts.df%>% filter(Year == 2019), aes(Week, y = Hits)) +
  geom_tile(aes(fill = Freq), color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue", trans = "log",
                      name = "retweet count (log scale)", 
                      limit = c(min_f,max_f)) + 
  labs(title = "Heat Map 2019", x = "week", y = "query term") + theme_grey(base_size = base_size)

p17 <- ggplotGrob(p_17)
p18 <- ggplotGrob(p_18)
p19 <- ggplotGrob(p_19)

heatmap_top_100_count <- rbind(p17, p18, p19, size = "last")
grid.newpage()
grid.draw(heatmap_top_100_count)

# bar plot separate by years
library(gtable)
library(grid)
count_17 <- ggplot(counts.df %>% filter(Year == 2017), aes(y = Freq, x = Week, fill = Hits)) + 
  geom_bar(stat = "identity") + ggtitle('Total Tweet Count time series 2017')  
count_18 <- ggplot(counts.df %>% filter(Year == 2018), aes(y = Freq, x = Week, fill = Hits)) + 
  geom_bar(stat = "identity") + ggtitle('Total Tweet Count time series 2018')
count_19 <- ggplot(counts.df %>% filter(Year == 2019), aes(y = Freq, x = Week, fill = Hits)) + 
  geom_bar(stat = "identity") + ggtitle('Total Tweet Count time series 2019')

c17 <- ggplotGrob(count_17)
c18 <- ggplotGrob(count_18)
c19 <- ggplotGrob(count_19)

count_full<- rbind(c17, c18, c19, size = "last")
grid.newpage()
grid.draw(count_full)
```
```{r}
## output multiple-figures

multiplot(p11,p12,p21,p22, cols = 2)

```
```{r}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


