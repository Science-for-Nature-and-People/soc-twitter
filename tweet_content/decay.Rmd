---
title: "decay"
author: "Meilin"
date: "8/14/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### This Markdown aims to visualize the decay of retweets and plot interactive/static network diagrams of users during Soil Health Summit 2019 conference.

```{r}
# load packages
library(tidyverse)
library(RColorBrewer)
library(tidytext)
library(stringr)
library(ggraph)
library(igraph)
library(tm)
library(NLP)
library(quanteda)
library(lubridate)
library(dplyr)
library(ggplot2)
source("../text_analysis_functions.R")

# load data
noRT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v4/twitter_merged_noRT_v4.csv", stringsAsFactors = FALSE)
RT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v4/twitter_merged_v4.csv",stringsAsFactors = FALSE)
```


### noRT dataset
```{r}
noRT_no_india <- clean_data(noRT, rm_pope = T, rm_india = T) %>% 
  #### get rid of weird overlapping duplicates
  group_by(created_at, screen_name, text) %>% 
  filter(retweet_count == max(retweet_count)) %>% 
  ungroup() %>% 
  distinct()
RT_no_india <- clean_data(RT, rm_pope = T, rm_india = T)
```

### select the SHS 2019 conference
```{r}
# select tweets with hashtag
# #SoilSummit19

input <- noRT_no_india

# SoilSummit19 is used by three conferences (Soil Health Summit 19, TCM Soil Summit, Red River Soil Health Summit)
#!!!!! could not reproduce this using "soilsummit19" => removed the 19
SHS19 <- input %>% 
  dplyr::filter(str_detect(tolower(text), "soilsummit"))
# to remove possible tweets from two other conferences also using this hashtag
SHS19 <- SHS19 %>% filter(date(SHS19$created_at) < "2019-01-25")

SHS19$conference <- "SHS19"
# select the noRT with retweet count > 1
SHS19_n <- SHS19 %>% filter(retweet_count > 1)


# select the RT of SHS19
SHS19_RT <- RT_no_india %>% filter(str_detect(tolower(text), "soilsummit"))
SHS19_RT <- SHS19_RT %>% filter (is_retweet == TRUE)
SHS19_RT <- SHS19_RT  %>% filter (retweet_count > 1)

# to remove possible RT from two other conferences also using this hashtag
SHS19_RT <- SHS19_RT %>% filter(date(SHS19_RT$created_at) < "2019-02-11")
```

```{r}
# barplot to show time series on retweet counts
ggplot(SHS19, aes(y = retweet_count, x = date(created_at), fill = conference)) + 
  geom_bar(stat = "identity") + ggtitle('Soil Health Summit 2019 Tweets')
```

```{r}
# barplot to show time series on total tweets counts
SHS19$date <- date(SHS19$created_at)

Event_19 <- data.frame(SHS19$date, SHS19$conference)
names(Event_19) <- c("date","Conference")

#count value based on week and query words
library(plyr)
counts.df <- ddply(Event_19, .(Event_19$date, Event_19$Conference), nrow)
names(counts.df) <- c("Date", "Conference", "Freq")

ggplot(counts.df, aes(y = Freq, x = Date, fill = Conference)) + 
  geom_bar(stat = "identity") + ggtitle('Number of Tweets on SHS 2019')
```

### select the retweeted tweets during SHS19 conference

```{r}
# write a function to find retweet and plot decay for certain tweet based on retweet count rank

library(plyr)

find_rt <- function(rank, noRT_dataset, RT_dataset) {
  result_rt <- RT_dataset %>% 
    filter(substring(RT_dataset$text, 1, 30) == substring(noRT_dataset$text[rank], 1, 30))
  # aggregate tweets by date
  result.df <- ddply(result_rt, .(date(result_rt$created_at), result_rt$query), nrow)
  names(result.df) <- c("Date", "Query", "Number")
  result.df <- result.df %>% arrange (result.df$Date)
  # calculate day_since based on the original tweet (noRT) date
  result.df$time_since <- result.df$Date - date(noRT_dataset$created_at[rank])
  result.df$content <- substring(result_rt$text[1], 1, 30)
  names(result.df) <- c("Date", "Query", "Number", "Time_since", "Content")
  return(result.df)
}
```

```{r}
SHS19_n <- SHS19_n %>% 
  arrange(-favorite_count)
pal <- colorRampPalette(c("blue", "red"))
cols <- pal(nrow(SHS19_n))

# find all retweet decay for SHS19
test <- find_rt(1, SHS19_n, SHS19_RT)

#plot the first tweet
g <- ggplot() + geom_line(data = test, aes(x = Time_since, y = Number, color = Content), color = cols[1]) + xlim(0,3) + 
  xlab("Time Since (days)") + ylab("Number of tweets")

# a loop to find all retweets for SHS19 tweets and plot decay
i <- 2
while(i < nrow(SHS19_n)){
  tmp <- find_rt(i, SHS19_n, SHS19_RT)
  # plot a line for retweet decay in each loop 
  g <- g + geom_line(data = tmp, aes(x = Time_since, y = Number, color = Content), color = cols[i+1]) + xlim(0,3)
  test <- rbind(test, tmp)
  i = i + 1
}

g + ggtitle("Retweet decay during SHS 2019")
```



-------------------------------------------------------
### Network Diagram
```{r}
# select input
# limiting the tweets for retweet_count > 1
SHS19_RT <- SHS19_RT %>% filter(SHS19_RT$retweet_count > 5)
tt <- data.frame(SHS19_RT$text, SHS19_RT$screen_name)
names(tt) <- c("text", "retweet_user")
tt$author <- SHS19$screen_name[match(tt$text, SHS19$text)]

# filter out the ones w/o authors
network <- tt %>% filter(tt$author != "NA")
```

# tweet/RT user network visualization
```{r}
# generate node list
authors <- network %>% distinct(author) 
names(authors) <- "label"
retweet_users <- network %>% distinct(retweet_user) 
names(retweet_users) <- "label"

nodes <- rbind(authors, retweet_users)
nodes <- nodes %>% distinct(label) #to get rid of duplicates in both authors and retweet user
nodes <- nodes %>% rowid_to_column("id")

# generate edge list
library(plyr)
per_route <- ddply(network, .(network$author, network$retweet_user), nrow)
names(per_route) <- c("authors", "retweet_users", "weight")

edges <- per_route %>% left_join(nodes, by = c("authors" = "label"))
colnames(edges)[4] <- "from"
edges <- edges %>% 
  left_join(nodes, by = c("retweet_users" = "label"))
colnames(edges)[5] <- "to"

edges <- dplyr::select(edges, from, to, weight)

```

```{r}
# interactive diagram
library(visNetwork)
library(networkD3)

graph <- graph.data.frame(edges, directed = T)
edges$value <- edges$weight
degree_value <- degree(graph, mode = "in")
nodes$value <- degree_value[match(nodes$id, names(degree_value))]

visNetwork(nodes, edges)
```

```{r}
# interactive network diagram with direction
visNetwork(nodes, edges) %>% 
  visIgraphLayout(layout = "layout_with_fr") %>% 
  visEdges(arrows = "middle")
```

# static network diagram
```{r, fig.width= 16, fig.height= 12}
# ggraph packages to show network diagram
library(tidygraph)
library(ggraph)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

routes_tidy %>% 
  activate(edges) %>% 
  dplyr::arrange(desc(weight))

ggraph(routes_tidy, layout = "graphopt") + 
  geom_node_point(aes(size = value)) +
  geom_edge_link(aes(width = weight), alpha = 0.8) + 
  scale_edge_width(range = c(0.1, 0.5)) +
  geom_node_text(aes(label = label), label.size = 0.25, repel = TRUE) +
  labs(edge_width = "Number") +
  theme_graph()

```


#### decay
```{r decay data, fig.width=12}

noRT_clean <- clean_data(noRT, rm_pope = T, rm_india = T)
RT_clean <- clean_data(RT, rm_pope = T, rm_india = T)


## set limit for number of retweets
limit <- 10

rt_limit <- noRT_clean %>% 
  filter(retweet_count > limit) %>% 
  dplyr::select(created_at, user_id, screen_name, text) %>% 
  distinct()



decay <- list()

## identify rts
# this will take a while baed on what rt_limit is set
for (i in 1:nrow(rt_limit)) {
  tmp <- find_rt(i, rt_limit, RT_clean)
  tmp <- tmp %>% 
    mutate(
      prop = round(number/sum(number),4)
    )
  decay[[i]] <- tmp
  
  if(i %% 500 == 0) {
    print(i)
  }
}

test <- bind_rows(decay)

names(test) <- tolower(names(test))

summ <- test %>% 
  group_by(time_since) %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
  dplyr::summarise(
    mean = round(mean(prop),4),
    sd = round(sd(prop),2)
  )

```

```{r decay box, fig.width=12, fig.height=5}
ggplot(summ, aes(as.factor(time_since), mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                 position=position_dodge(.9)) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month")

### get only one month and remove spaces and hashtags
box <- test %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
    mutate(query = str_replace_all(query, "#| |\"", ""))

###combining soilhealth and healthysoil
box$query[box$query == "healthysoil"] <- "soilhealth"
box$query[box$query == "healthyrangelands"] <- "rangelandhealth"


# define which search terms you want to include
terms <- c("soilhealth", "regenerativeagriculture")

box_sub <- filter(box, query %in% terms)

ggplot(box_sub, aes(as.factor(time_since), prop)) +
  geom_boxplot(outlier.shape = NA) +
  scale_x_discrete(breaks=pretty(box$time_since,n=10)) +
  facet_wrap(~query) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month for tweets with >10 RTs") +
  theme_bw()
  


ggplot(box, aes(as.factor(time_since), prop)) +
  geom_boxplot(outlier.shape = NA) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month")


```


## average for all tweets (with regression/CI):
```{r decay line, fig.width=12}
### finding standard error
se <- test %>% 
  group_by(time_since) %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
  dplyr::summarise(
    mean = round(mean(prop),4),
    se = round(sqrt(var(prop)/length(prop)), 2)
  )

##plotting SE
ggplot(se, aes(time_since, mean)) +
  geom_point() +
  geom_line() +
  geom_ribbon(aes(ymin = mean-2*se, ymax = mean+2*se), alpha = .3) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month") +
  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +
    scale_x_continuous(expand = c(0,0), breaks=pretty(summ$time_since,n=10)) 

## LOESS model
ggplot(summ, aes(time_since, mean)) +
  geom_smooth(method = "loess", linetype = 0) +
  geom_line() +
  geom_point() +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month") +
  scale_x_continuous(expand = c(0,0), breaks=pretty(summ$time_since,n=10)) +
  coord_cartesian(ylim = c(0, .6), expand = c(0,0)) 
```



#### RFSI RT network
```{r rfsi}
# select tweets with hashtag
# 

input <- noRT_no_india


RFSI <- input %>% 
  dplyr::filter(str_detect(tolower(text), "rfsi|rfsi19|invest_regenag|regenerative food systems investment") & 
                !str_detect(text, "#rye|SRFSI")) 
  

RFSI$conference <- "RFSI"
# select the noRT with retweet count > 1
RFSI_n <- RFSI %>% filter(retweet_count > 1)


# select the RT of RFSI
RFSI_RT <- RT_no_india %>% filter(str_detect(tolower(text),"#rfsi|rfsi|rfsi19|invest_regenag|regenerative food systems investment"))
RFSI_RT <- RFSI_RT %>% filter (is_retweet == TRUE)
RFSI_RT <- RFSI_RT  %>% filter (retweet_count > 1)

# remove 3 tweets unrelated to conference
RFSI_RT <- RFSI_RT %>% filter(!str_detect(text, "#rye|SRFSI"))

# select input
# limiting the tweets for retweet_count > 1
RFSI_RT <- RFSI_RT %>% filter(RFSI_RT$retweet_count > 1)
tt <- data.frame(RFSI_RT$text, RFSI_RT$screen_name)
names(tt) <- c("text", "retweet_user")
tt$author <- RFSI$screen_name[match(tt$text, RFSI$text)]

# filter out the ones w/o authors
network <- tt %>% filter(tt$author != "NA")


# generate node list
authors <- network %>% distinct(author) 
names(authors) <- "label"
retweet_users <- network %>% distinct(retweet_user) 
names(retweet_users) <- "label"

nodes <- rbind(authors, retweet_users)
nodes <- nodes %>% distinct(label) #to get rid of duplicates in both authors and retweet user
nodes <- nodes %>% rowid_to_column("id")

# generate edge list
library(plyr)
per_route <- ddply(network, .(network$author, network$retweet_user), nrow)
names(per_route) <- c("authors", "retweet_users", "weight")

edges <- per_route %>% left_join(nodes, by = c("authors" = "label"))
colnames(edges)[4] <- "from"
edges <- edges %>% 
  left_join(nodes, by = c("retweet_users" = "label"))
colnames(edges)[5] <- "to"

edges <- dplyr::select(edges, from, to, weight)

graph <- graph.data.frame(edges, directed = T)
edges$value <- edges$weight
degree_value <- degree(graph, mode = "in")
nodes$value <- degree_value[match(nodes$id, names(degree_value))]

# ggraph packages to show network diagram
library(tidygraph)
library(ggraph)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

routes_tidy %>% 
  activate(edges) %>% 
  dplyr::arrange(desc(weight))

ggraph(routes_tidy, layout = "graphopt") + 
  geom_node_point(aes(size = value)) +
  geom_edge_link(aes(width = weight), alpha = 0.8) + 
  scale_edge_width(range = c(0.1, 0.5)) +
  geom_node_text(aes(label = label), label.size = 0.25, repel = TRUE) +
  labs(edge_width = "Number") +
  theme_graph()
```




#### REGEN RT network
```{r REGEN}
# select tweets with hashtag
# 

input <- noRT_no_india


REGEN <- input %>%
  dplyr::filter(str_detect(tolower(text), "#regenerate2018"),
                str_detect(tolower(hashtags), "regenerate2018"))
  

REGEN$conference <- "REGEN"
# select the noRT with retweet count > 1
REGEN_n <- REGEN %>% filter(retweet_count > 1)


# select the RT of REGEN
REGEN_RT <- RT_no_india %>% filter(str_detect(tolower(text),"#REGEN|REGEN|REGEN19|invest_regenag|regenerative food systems investment"))
REGEN_RT <- REGEN_RT %>% filter (is_retweet == TRUE)
REGEN_RT <- REGEN_RT  %>% filter (retweet_count > 1)

# remove 3 tweets unrelated to conference
REGEN_RT <- REGEN_RT %>% filter(!str_detect(text, "#rye|SREGEN"))

# select input
# limiting the tweets for retweet_count > 1
REGEN_RT <- REGEN_RT %>% filter(REGEN_RT$retweet_count > 1)
tt <- data.frame(REGEN_RT$text, REGEN_RT$screen_name)
names(tt) <- c("text", "retweet_user")
tt$author <- REGEN$screen_name[match(tt$text, REGEN$text)]

# filter out the ones w/o authors
network <- tt %>% filter(tt$author != "NA")


# generate node list
authors <- network %>% distinct(author) 
names(authors) <- "label"
retweet_users <- network %>% distinct(retweet_user) 
names(retweet_users) <- "label"

nodes <- rbind(authors, retweet_users)
nodes <- nodes %>% distinct(label) #to get rid of duplicates in both authors and retweet user
nodes <- nodes %>% rowid_to_column("id")

# generate edge list
library(plyr)
per_route <- ddply(network, .(network$author, network$retweet_user), nrow)
names(per_route) <- c("authors", "retweet_users", "weight")

edges <- per_route %>% left_join(nodes, by = c("authors" = "label"))
colnames(edges)[4] <- "from"
edges <- edges %>% 
  left_join(nodes, by = c("retweet_users" = "label"))
colnames(edges)[5] <- "to"

edges <- dplyr::select(edges, from, to, weight)

graph <- graph.data.frame(edges, directed = T)
edges$value <- edges$weight
degree_value <- degree(graph, mode = "in")
nodes$value <- degree_value[match(nodes$id, names(degree_value))]

# ggraph packages to show network diagram
library(tidygraph)
library(ggraph)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

routes_tidy %>% 
  activate(edges) %>% 
  dplyr::arrange(desc(weight))

ggraph(routes_tidy, layout = "graphopt") + 
  geom_node_point(aes(size = value)) +
  geom_edge_link(aes(width = weight), alpha = 0.8) + 
  scale_edge_width(range = c(0.1, 0.5)) +
  geom_node_text(aes(label = label), label.size = 0.25, repel = TRUE) +
  labs(edge_width = "Number") +
  theme_graph()
```