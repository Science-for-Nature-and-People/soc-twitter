---
title: "decay"
author: "Meilin"
date: "8/14/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### This Markdown aims to visualize the decay of retweets and plot interactive/static network diagrams of users during Soil Health Summit 2019 conference.

```{r}
# load packages
library(tidyverse)
library(RColorBrewer)
library(tidytext)
library(stringr)
library(ggraph)
library(igraph)
library(tm)
library(NLP)
library(quanteda)
library(lubridate)
library(dplyr)
library(ggplot2)
source("../text_analysis_functions.R")

# load data
noRT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v3/twitter_merged_noRT_v3.csv", stringsAsFactors = FALSE)
RT <- read.csv("/home/shares/soilcarbon/Twitter/Merged_v3/twitter_merged_v3.csv",stringsAsFactors = FALSE)
```


### noRT dataset
```{r}
noRT_no_india <- clean_data(noRT, rm_pope = T, rm_india = T)
RT_no_india <- clean_data(RT, rm_pope = T, rm_india = T)
```

### select the SHS 2019 conference
```{r}
# select tweets with hashtag
# #SoilSummit19

input <- noRT_no_india

# SoilSummit19 is used by three conferences (Soil Health Summit 19, TCM Soil Summit, Red River Soil Health Summit)
#!!!!! could not reproduce this using "soilsummit19" => removed the 19
SHS19 <- input %>% 
  dplyr::filter(str_detect(tolower(text), "soilsummit"))
# to remove possible tweets from two other conferences also using this hashtag
SHS19 <- SHS19 %>% filter(date(SHS19$created_at) < "2019-01-25")

SHS19$conference <- "SHS19"
# select the noRT with retweet count > 1
SHS19_n <- SHS19 %>% filter(retweet_count > 1)


# select the RT of SHS19
SHS19_RT <- RT_no_india %>% filter(str_detect(tolower(text), "soilsummit"))
SHS19_RT <- SHS19_RT %>% filter (is_retweet == TRUE)
SHS19_RT <- SHS19_RT  %>% filter (retweet_count > 1)

# to remove possible RT from two other conferences also using this hashtag
SHS19_RT <- SHS19_RT %>% filter(date(SHS19_RT$created_at) < "2019-02-11")
```

```{r}
# barplot to show time series on retweet counts
ggplot(SHS19, aes(y = retweet_count, x = date(created_at), fill = conference)) + 
  geom_bar(stat = "identity") + ggtitle('Soil Health Summit 2019 Tweets')
```

```{r}
# barplot to show time series on total tweets counts
SHS19$date <- date(SHS19$created_at)

Event_19 <- data.frame(SHS19$date, SHS19$conference)
names(Event_19) <- c("date","Conference")

#count value based on week and query words
library(plyr)
counts.df <- ddply(Event_19, .(Event_19$date, Event_19$Conference), nrow)
names(counts.df) <- c("Date", "Conference", "Freq")

ggplot(counts.df, aes(y = Freq, x = Date, fill = Conference)) + 
  geom_bar(stat = "identity") + ggtitle('Number of Tweets on SHS 2019')
```

### select the retweeted tweets during SHS19 conference

```{r}
# write a function to find retweet and plot decay for certain tweet based on retweet count rank

library(plyr)

find_rt <- function(rank, noRT_dataset, RT_dataset) {
  result_rt <- RT_dataset %>% 
    filter(substring(RT_dataset$text, 1, 30) == substring(noRT_dataset$text[rank], 1, 30))
  # aggregate tweets by date
  result.df <- ddply(result_rt, .(date(result_rt$created_at), result_rt$query), nrow)
  names(result.df) <- c("Date", "Query", "Number")
  result.df <- result.df %>% arrange (result.df$Date)
  # calculate day_since based on the original tweet (noRT) date
  result.df$time_since <- result.df$Date - date(noRT_dataset$created_at[rank])
  result.df$content <- substring(result_rt$text[1], 1, 30)
  names(result.df) <- c("Date", "Query", "Number", "Time_since", "Content")
  return(result.df)
}
```

```{r}
SHS19_n <- SHS19_n %>% 
  arrange(-favorite_count)
pal <- colorRampPalette(c("blue", "red"))
cols <- pal(nrow(SHS19_n))

# find all retweet decay for SHS19
test <- find_rt(1, SHS19_n, SHS19_RT)

#plot the first tweet
g <- ggplot() + geom_line(data = test, aes(x = Time_since, y = Number, color = Content), color = cols[1]) + xlim(0,3) + 
  xlab("Time Since (days)") + ylab("Number of tweets")

# a loop to find all retweets for SHS19 tweets and plot decay
i <- 2
while(i < nrow(SHS19_n)){
  tmp <- find_rt(i, SHS19_n, SHS19_RT)
  # plot a line for retweet decay in each loop 
  g <- g + geom_line(data = tmp, aes(x = Time_since, y = Number, color = Content), color = cols[i+1]) + xlim(0,3)
  test <- rbind(test, tmp)
  i = i + 1
}

g + ggtitle("Retweet decay during SHS 2019")
```



-------------------------------------------------------
### Network Diagram
```{r}
# select input
# limiting the tweets for retweet_count > 1
SHS19_RT <- SHS19_RT %>% filter(SHS19_RT$retweet_count > 2)
tt <- data.frame(SHS19_RT$text, SHS19_RT$screen_name)
names(tt) <- c("text", "retweet_user")
tt$author <- SHS19$screen_name[match(tt$text, SHS19$text)]

# filter out the ones w/o authors
network <- tt %>% filter(tt$author != "NA")
```

# tweet/RT user network visualization
```{r}
# generate node list
authors <- network %>% distinct(author) 
names(authors) <- "label"
retweet_users <- network %>% distinct(retweet_user) 
names(retweet_users) <- "label"

nodes <- rbind(authors, retweet_users)
nodes <- nodes %>% distinct(label) #to get rid of duplicates in both authors and retweet user
nodes <- nodes %>% rowid_to_column("id")

# generate edge list
library(plyr)
per_route <- ddply(network, .(network$author, network$retweet_user), nrow)
names(per_route) <- c("authors", "retweet_users", "weight")

edges <- per_route %>% left_join(nodes, by = c("authors" = "label"))
colnames(edges)[4] <- "from"
edges <- edges %>% 
  left_join(nodes, by = c("retweet_users" = "label"))
colnames(edges)[5] <- "to"

edges <- dplyr::select(edges, from, to, weight)

```

```{r}
# interactive diagram
library(visNetwork)
library(networkD3)

graph <- graph.data.frame(edges, directed = T)
edges$value <- edges$weight
degree_value <- degree(graph, mode = "in")
nodes$value <- degree_value[match(nodes$id, names(degree_value))]

visNetwork(nodes, edges)
```

```{r}
# interactive network diagram with direction
visNetwork(nodes, edges) %>% 
  visIgraphLayout(layout = "layout_with_fr") %>% 
  visEdges(arrows = "middle")
```

# static network diagram
```{r, fig.width= 16, fig.height= 12}
# ggraph packages to show network diagram
library(tidygraph)
library(ggraph)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

routes_tidy %>% 
  activate(edges) %>% 
  dplyr::arrange(desc(weight))

ggraph(routes_tidy, layout = "graphopt") + 
  geom_node_point(aes(size = value)) +
  geom_edge_link(aes(width = weight), alpha = 0.8) + 
  scale_edge_width(range = c(0.1, 0.5)) +
  geom_node_text(aes(label = label), label.size = 0.25, repel = TRUE) +
  labs(edge_width = "Number") +
  theme_graph()

```


##### Kyles additions:

### network for top 4 tweets
```{r, fig.width=12, fig.height=12}
RT_clean <- clean_data(RT, rm_pope = T, rm_india = T)
noRT_clean <- clean_data(noRT, rm_pope = T, rm_india = T)


top100 <- noRT_clean %>% 
  arrange(desc(retweet_count)) %>% 
  head(100) %>% 
  select(text, screen_name) %>% 
  dplyr::rename("author" = "screen_name")

top_regen <- noRT %>% 
  filter(query == "regenerative agriculture") %>% 
  select(text, screen_name) %>% 
  dplyr::rename("author" = "screen_name")



retweets <- RT_clean %>% 
  filter(is_retweet == TRUE & retweet_count > 1) %>% 
  select(screen_name, text)

joined <- dplyr::left_join(retweets, top100)


network <- filter(joined, !is.na(author))

authors <- network %>% dplyr::distinct(author) 
names(authors) <- "label"
retweet_users <- network %>% dplyr::distinct(screen_name) 
names(retweet_users) <- "label"

nodes <- rbind(authors, retweet_users)
nodes <- nodes %>% distinct(label) #to get rid of duplicates in both authors and retweet user
nodes <- nodes %>% rowid_to_column("id")

# generate edge list
library(plyr)
per_route <- ddply(network, .(network$author, network$screen_name), nrow)
names(per_route) <- c("label", "retweet_users", "weight")

edges <- per_route %>% 
  dplyr::left_join(nodes)

colnames(edges)[4] <- "from"
edges <- edges %>% 
  left_join(nodes, by = c("retweet_users" = "label"))
colnames(edges)[5] <- "to"

edges <- dplyr::select(edges, from, to, weight)


library(tidygraph)
library(ggraph)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)


test <- routes_tidy %>% 
  mutate(community = group_walktrap(weights = weight)) %>% 
  mutate(centrality = centrality_degree(weights = weight)) %>% 
  arrange(community, centrality) 

labs <- test %>% 
  mutate(ranking = row_number()) %>% 
  dplyr::top_n(500, centrality) %>% 
  mutate(node_label = if_else(centrality > 150, label, "")) %>% 
  mutate(node_size = if_else(centrality > 150, centrality, 0)) 

test %>%
  activate(nodes) %>%
  arrange(desc(centrality))


ggraph(labs, layout = 'linear', circular = TRUE) + 
  geom_edge_arc(alpha=0.05, 
                aes(col = factor(weight), edge_width = weight)) +
  geom_node_label(aes(label=node_label, 
                      size=node_size, 
                      col = factor(community)),
                  label.size=0, 
                  fill="#ffffff66", 
                  segment.colour="slateblue",
                  color="black", 
                  repel=TRUE, 
                  #fontface="bold", 
                  show.legend = FALSE) +
  coord_fixed() +
  scale_size_area(trans="sqrt") +
  labs(title="Retweet Network", 
       subtitle="most central users associated with the 100 most RTed tweets") +
  theme_graph() +
  guides(edge_width = FALSE, 
         edge_colour = guide_legend(title = "Edge weights",
                                    override.aes = list(edge_alpha = 1))) +
  theme(legend.position="bottom", 
        plot.title = element_text(size = rel(3)),
        plot.subtitle = element_text(size = rel(2)),
        legend.text = element_text(size = rel(2)))

```



#### decay
```{r decay data, fig.width=12}

noRT_no_india <- clean_data(noRT, rm_pope = T, rm_india = T)
RT_no_india <- clean_data(RT, rm_pope = T, rm_india = T)


## set limit for number of retweets
rt_limit <- 10

rt_limit <- noRT_clean %>% 
  filter(retweet_count > rt_limit)



decay <- list()

## identify rts
# this will take a while what rt_limit is set
for (i in 1:nrow(rt_limit)) {
  tmp <- find_rt(i, rt_limit, RT_clean)
  tmp <- tmp %>% 
    mutate(
      prop = round(number/sum(number),4)
    )
  decay[[i]] <- tmp
  
}

test <- bind_rows(decay)

summ <- test %>% 
  group_by(time_since) %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
  dplyr::summarise(
    mean = round(mean(prop),4),
    sd = round(sd(prop),2)
  )

```

```{r decay box, fig.width=12, fig.height=5}
ggplot(summ, aes(as.factor(time_since), mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2,
                 position=position_dodge(.9)) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month")

### get only one month and remove spaces and hashtags
box <- test %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
    mutate(query = str_replace_all(query, "#| |\"", ""))

###combining soilhealth and healthysoil
box$query[box$query == "healthysoil"] <- "soilhealth"

# define which search terms you want to include
terms <- c("soilhealth", "rangelandhealth", "regenerativeagriculture")

box_sub <- filter(box, query %in% terms)

ggplot(box_sub, aes(as.factor(time_since), prop)) +
  geom_boxplot(outlier.shape = NA) +
  scale_x_discrete(breaks=pretty(box$time_since,n=10)) +
  facet_wrap(~query) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month for tweets with >10 RTs") +
  theme_bw()
  


ggplot(box, aes(as.factor(time_since), prop)) +
  geom_boxplot(outlier.shape = NA) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month")


```


## average for all tweets (with regression/CI):
```{r decay line, fig.width=12}
### finding standard error
se <- test %>% 
  group_by(time_since) %>% 
  filter(time_since <= 31 & time_since >= 0) %>% 
  dplyr::summarise(
    mean = round(mean(prop),4),
    se = round(sqrt(var(prop)/length(prop)), 2)
  )

##plotting SE
ggplot(se, aes(time_since, mean)) +
  geom_point() +
  geom_line() +
  geom_ribbon(aes(ymin = mean-2*se, ymax = mean+2*se), alpha = .3) +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month") +
  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +
    scale_x_continuous(expand = c(0,0), breaks=pretty(summ$time_since,n=10)) 

## LOESS model
ggplot(summ, aes(time_since, mean)) +
  geom_smooth(method = "loess", linetype = 0) +
  geom_line() +
  geom_point() +
  labs(x = "days since first tweet",
       y = "proportion of total retweets",
       title = "Average retweet decay over 1 month") +
  scale_x_continuous(expand = c(0,0), breaks=pretty(summ$time_since,n=10)) +
  coord_cartesian(ylim = c(0, .6), expand = c(0,0)) 
```